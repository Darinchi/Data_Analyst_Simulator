{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "import pandahouse as ph\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context\n",
    "\n",
    "\n",
    "#параметры соединения \n",
    "connection_from = {'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                  'database':'simulator_20231113',\n",
    "                   'user':'student',\n",
    "                   'password':'dpo_python_2020'\n",
    "}\n",
    "\n",
    "# передаем в схему test\n",
    "connection_to = {'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                'database':'test',\n",
    "                 'user':'student-rw', \n",
    "                 'password':'11111111' \n",
    "}\n",
    "\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'd-kulikova', # Владелец операции \n",
    "    'depends_on_past': False, # Зависимость от прошлых запусков\n",
    "    'retries': 2, # Кол-во попыток выполнить DAG\n",
    "    'retry_delay': timedelta(minutes=5), # Промежуток между перезапусками\n",
    "    'start_date': datetime(2023, 10, 1), # Дата начала выполнения DAG\n",
    "}\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '@daily'\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_kulikova():\n",
    "\n",
    "    @task()\n",
    "    def extract1():\n",
    "        query = \"\"\"SELECT user_id, \n",
    "                          event_date, \n",
    "                          if(gender=0, 'male', 'female') as gender, \n",
    "                          age, \n",
    "                          os, \n",
    "                          likes, \n",
    "                          views\n",
    "                   FROM\n",
    "                     (SELECT DISTINCT(user_id), \n",
    "                             gender, \n",
    "                             age, \n",
    "                             os\n",
    "                      FROM {db}.feed_actions) as t1\n",
    "                  JOIN\n",
    "                     (SELECT user_id, \n",
    "                             countIf(action='like') as likes,\n",
    "                             countIf(action='view') as views,\n",
    "                             toDate(time) as event_date\n",
    "                      FROM {db}.feed_actions \n",
    "                      WHERE toDate(time) = yesterday() \n",
    "                      GROUP BY user_id, \n",
    "                               event_date) as t2\n",
    "\n",
    "                   USING(user_id)\n",
    "                \"\"\"\n",
    "        \n",
    "        df_cube1 = ph.read_clickhouse(query, connection = connection_from)\n",
    "        return df_cube1\n",
    "\n",
    "    \n",
    "    @task()\n",
    "    def extract2():\n",
    "        query = '''\n",
    "                SELECT user_id,\n",
    "                       event_date,\n",
    "                       age, \n",
    "                       gender, \n",
    "                       os,\n",
    "                       messages_received, \n",
    "                       messages_sent,\n",
    "                       users_sent,\n",
    "                       users_received\n",
    "                FROM \n",
    "                   (SELECT user_id, \n",
    "                           event_date,      \n",
    "                           messages_received, \n",
    "                           messages_sent,\n",
    "                           users_sent,\n",
    "                           users_received\n",
    "                    FROM \n",
    "                        (SELECT user_id, \n",
    "                                count(receiver_id) as messages_sent,     \n",
    "                                count(DISTINCT(receiver_id)) as users_sent,\n",
    "                                toDate(time) as event_date\n",
    "                         FROM {db}.message_actions\n",
    "                         WHERE toDate(time) = yesterday() \n",
    "                         GROUP BY user_id, \n",
    "                                  event_date) as t1\n",
    "                   JOIN\n",
    "                      (SELECT receiver_id,\n",
    "                              count(user_id) as messages_received, \n",
    "                              count(DISTINCT(user_id)) as users_received,\n",
    "                              toDate(time) as event_date\n",
    "                       FROM {db}.message_actions\n",
    "                       WHERE toDate(time) = yesterday() \n",
    "                       GROUP BY receiver_id, event_date) as t2\n",
    "                    ON t1.user_id = t2.receiver_id) t1_2\n",
    "                   JOIN\n",
    "                       (SELECT DISTINCT(user_id), \n",
    "                               if(gender=0, 'male', 'female') as gender, \n",
    "                               age, \n",
    "                               os\n",
    "                        FROM {db}.message_actions) as t3\n",
    "\n",
    "                   USING(user_id)\n",
    "                '''\n",
    "        \n",
    "        df_cube2 = ph.read_clickhouse(query, connection = connection_from)\n",
    "        return df_cube2\n",
    "      \n",
    "    @task\n",
    "    def transform_merging(df1, df2):\n",
    "        df = df1.merge(df2, how='outer', on=['user_id','event_date', 'gender', 'os', 'age']).fillna(0)\n",
    "        return df   \n",
    "    \n",
    "    @task\n",
    "    def transform_gender(df_cube):\n",
    "        df_cube_gender = df_cube[['event_date', 'gender', 'likes', 'views', 'messages_received', 'messages_sent', 'users_sent',                 'users_received']]\\\n",
    "            .groupby(['event_date', 'gender'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_cube_gender = df_cube_gender.melt(id_vars=['event_date',  'likes', 'views', 'messages_received', 'messages_sent',                   'users_sent', 'users_received'],\n",
    "                                var_name='dimension', value_name='dimension_value')\n",
    "        return df_cube_gender\n",
    "   \n",
    "    @task\n",
    "    def transform_os(df_cube):\n",
    "        df_cube_os = df_cube[['event_date', 'os', 'likes', 'views', 'messages_received', 'messages_sent', 'users_sent',                         'users_received']]\\\n",
    "            .groupby(['event_date', 'os'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_cube_os = df_cube_os.melt(id_vars=['event_date',  'likes', 'views', 'messages_received', 'messages_sent', 'users_sent',             'users_received'],\n",
    "                                var_name='dimension', value_name='dimension_value')\n",
    "        return df_cube_os\n",
    "    \n",
    "    @task\n",
    "    def transform_age(df_cube):\n",
    "        df_cube_age = df_cube[['event_date', 'age', 'likes', 'views', 'messages_received', 'messages_sent', 'users_sent',                       'users_received']]\\\n",
    "            .groupby(['event_date', 'age'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        df_cube_age = df_cube_age.melt(id_vars=['event_date',  'likes', 'views', 'messages_received', 'messages_sent', 'users_sent',           'users_received'],\n",
    "                                var_name='dimension', value_name='dimension_value')\n",
    "        return df_cube_age\n",
    "        \n",
    "    @task\n",
    "    def transform_concat_dfs(df_cube_os, df_cube_gender, df_cube_age):\n",
    "        concat_dfs = pd.concat([df_cube_os, df_cube_gender, df_cube_age], axis=0)\n",
    "        concat_dfs = concat_dfs[['event_date', 'dimension', 'dimension_value', 'likes', 'views', 'messages_received', 'messages_sent',               'users_sent', 'users_received']]\n",
    "        concat_dfs = concat_dfs.astype({'views':'int64',\n",
    "                        'likes':'int64',\n",
    "                        'messages_received':'int64',\n",
    "                        'messages_sent':'int64',\n",
    "                        'users_received':'int64',\n",
    "                        'users_sent':'int64'})\n",
    "\n",
    "        return concat_dfs\n",
    "    \n",
    "    @task\n",
    "    def load(df_all):\n",
    "        query = '''CREATE TABLE IF NOT EXISTS test.d_kulikova\n",
    "            (event_date Date,\n",
    "            dimension String,\n",
    "            dimension_value String,\n",
    "            views Int64,\n",
    "            likes Int64,\n",
    "            messages_received Int64,\n",
    "            messages_sent Int64,\n",
    "            users_received Int64,\n",
    "            users_sent Int64           \n",
    "            )\n",
    "            ENGINE = MergeTree()\n",
    "            ORDER BY event_date\n",
    "            '''\n",
    "        ph.execute(query = query, connection = connection_to)\n",
    "        ph.to_clickhouse(df=df_all, table='d_kulikova', index=False, connection=connection_to)\n",
    "  \n",
    "    df_cube1 = extract1()\n",
    "    df_cube2 = extract2()\n",
    "    \n",
    "    df_cube = transform_merging(df_cube1, df_cube2)\n",
    "    \n",
    "    df_cube_gender = transform_gender(df_cube)\n",
    "    df_cube_os = transform_os(df_cube)\n",
    "    df_cube_age = transform_age(df_cube)\n",
    "    \n",
    "    df_all = transform_concat_dfs(df_cube_os, df_cube_gender, df_cube_age)\n",
    "    \n",
    "    load(df_all)\n",
    "\n",
    "dag_kulikova = dag_kulikova()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
